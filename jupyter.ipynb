{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m pip install --upgrade pip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m pip install --user sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Elevation                             float64\n",
       "Aspect                                float64\n",
       "Slope                                 float64\n",
       "Horizontal_Distance_To_Hydrology      float64\n",
       "Vertical_Distance_To_Hydrology        float64\n",
       "Horizontal_Distance_To_Roadways       float64\n",
       "Hillshade_9am                         float64\n",
       "Hillshade_Noon                        float64\n",
       "Hillshade_3pm                         float64\n",
       "Horizontal_Distance_To_Fire_Points    float64\n",
       "Wilderness_Area1                        int64\n",
       "Wilderness_Area2                        int64\n",
       "Wilderness_Area3                        int64\n",
       "Wilderness_Area4                        int64\n",
       "Soil_Type1                              int64\n",
       "Soil_Type2                              int64\n",
       "Soil_Type3                              int64\n",
       "Soil_Type4                              int64\n",
       "Soil_Type5                              int64\n",
       "Soil_Type6                              int64\n",
       "Soil_Type7                              int64\n",
       "Soil_Type8                              int64\n",
       "Soil_Type9                              int64\n",
       "Soil_Type10                             int64\n",
       "Soil_Type11                             int64\n",
       "Soil_Type12                             int64\n",
       "Soil_Type13                             int64\n",
       "Soil_Type14                             int64\n",
       "Soil_Type15                             int64\n",
       "Soil_Type16                             int64\n",
       "Soil_Type17                             int64\n",
       "Soil_Type18                             int64\n",
       "Soil_Type19                             int64\n",
       "Soil_Type20                             int64\n",
       "Soil_Type21                             int64\n",
       "Soil_Type22                             int64\n",
       "Soil_Type23                             int64\n",
       "Soil_Type24                             int64\n",
       "Soil_Type25                             int64\n",
       "Soil_Type26                             int64\n",
       "Soil_Type27                             int64\n",
       "Soil_Type28                             int64\n",
       "Soil_Type29                             int64\n",
       "Soil_Type30                             int64\n",
       "Soil_Type31                             int64\n",
       "Soil_Type32                             int64\n",
       "Soil_Type33                             int64\n",
       "Soil_Type34                             int64\n",
       "Soil_Type35                             int64\n",
       "Soil_Type36                             int64\n",
       "Soil_Type37                             int64\n",
       "Soil_Type38                             int64\n",
       "Soil_Type39                             int64\n",
       "Soil_Type40                             int64\n",
       "Cover_Type                              int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv(\"covtype.csv\")\n",
    "numsons = 0\n",
    "\"\"\"\n",
    "for col in dataset:\n",
    "    if numsons >= 10 and numsons != 54: \n",
    "    \n",
    "        dataset[col] = dataset[col].astype('bool')\n",
    "    numsons += 1\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "numsons2 = 0 \n",
    "for col in dataset:\n",
    "    if numsons2 < 10: \n",
    "    \n",
    "        dataset[col] = dataset[col].astype('float64')\n",
    "    numsons2 += 1\n",
    "\"\"\"\n",
    "store = []\n",
    "\n",
    "for data_item in dataset.Cover_Type:\n",
    "    if data_item == 1:\n",
    "        store += ['a']\n",
    "    if data_item == 2:\n",
    "        store += ['b']\n",
    "    if data_item == 3:\n",
    "        store += ['c']\n",
    "    if data_item == 4:\n",
    "        store += ['d']\n",
    "    if data_item == 5:\n",
    "        store += ['e']\n",
    "    if data_item == 6:\n",
    "        store += ['f']\n",
    "    if data_item == 7:\n",
    "        store += ['g']\n",
    "\n",
    "dataset.Cover_Type = store\n",
    "   \n",
    "    \n",
    "dataset.Cover_Type.astype('category')\n",
    "\n",
    "print(dataset.dtypes)\n",
    "\"\"\"\n",
    "dataset.dtypes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m pip install --user seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.groupby('Cover_Type').Vertical_Distance_To_Hydrology.hist()\n",
    "dataset.dropna(inplace=True)\n",
    "dataset.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "out_e = dataset['Elevation']\n",
    "out_elist = []\n",
    "out_elist2 = []\n",
    "for values in out_e:\n",
    "    out_elist += [values]\n",
    "    out_elist2 += [values]\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "\n",
    "sns.boxplot(data = dataset, y = 'Elevation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m pip install --user statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_elist.sort()\n",
    "q1, q3= np.percentile(out_elist,[25,75])\n",
    "\n",
    "iqr = q3 - q1\n",
    "lower_bound = q1 - (1.5 * iqr)\n",
    "upper_bound = q3 + (1.5 * iqr)\n",
    "print('lower_bound:',lower_bound)\n",
    "print('upper_bound:',upper_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = []\n",
    "\n",
    "for index in range(len(dataset.Elevation)):\n",
    "    if out_elist2[index]> upper_bound or out_elist2[index] < lower_bound:\n",
    "        outliers += [index]\n",
    "print(len(outliers))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_hori = dataset['Horizontal_Distance_To_Roadways']\n",
    "out_horilist = []\n",
    "out_horilist2 = []\n",
    "for values1 in out_hori:\n",
    "    out_horilist += [values1]\n",
    "    out_horilist2 += [values1]\n",
    "out_horilist.sort()\n",
    "new_q1, new_q3= np.percentile(out_horilist,[25,75])\n",
    "\n",
    "new_iqr = new_q3 - new_q1\n",
    "lower_bound1 = new_q1 - (1.5 * new_iqr)\n",
    "upper_bound1 = new_q3 + (1.5 * new_iqr)\n",
    "print('lower_bound:',lower_bound1)\n",
    "print('upper_bound:',upper_bound1)\n",
    "outliers2 = []\n",
    "\n",
    "for index1 in range(len(dataset.Horizontal_Distance_To_Roadways)):\n",
    "    if out_horilist2[index1]> upper_bound1 or out_horilist2[index1] < lower_bound1:\n",
    "        outliers2 += [index1]\n",
    "print(len(outliers2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('number of outliers(Elevation)',len(outliers))\n",
    "print('number of outliers(Horizontal_Distance_To_Roadways)',len(outliers2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')\n",
    "\n",
    "\n",
    "sns.boxplot(data = dataset, y = 'Horizontal_Distance_To_Roadways')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.describe(include='all').transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop(\"Cover_Type\",1)   #Feature Matrix\n",
    "Y = dataset[\"Cover_Type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import f_classif\n",
    "bestfeatures = SelectKBest(score_func=f_classif , k=10)\n",
    "\n",
    "\n",
    "fit = bestfeatures.fit(X,Y)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(X.columns)\n",
    "#concat two dataframes for better visualization \n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['Specs','Score']  #naming the dataframe columns\n",
    "print(featureScores.nlargest(10,'Score'))   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "\n",
    "sns.boxplot(data = dataset, x = 'Cover_Type', y = 'Elevation')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_list = []\n",
    "count_list2 = []\n",
    "for numsons in range(1,8):\n",
    "    count_n = 0\n",
    "    count_n2 = 0\n",
    "    for cc in range(len(dataset.Cover_Type)):\n",
    "        \n",
    "        if dataset.Cover_Type[cc] == numsons:\n",
    "            if dataset.Wilderness_Area4[cc] == True:\n",
    "                count_n += 1\n",
    "            else:\n",
    "                count_n2 += 1\n",
    "                \n",
    "                \n",
    "        \n",
    "    count_list += [count_n]\n",
    "    count_list2 += [count_n2]\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_list3 = []\n",
    "count_list4 = []\n",
    "for numsons in range(1,8):\n",
    "    count_n3 = 0\n",
    "    count_n4 = 0\n",
    "    for cc1 in range(len(dataset.Cover_Type)):\n",
    "        \n",
    "        if dataset.Cover_Type[cc1] == numsons:\n",
    "            if dataset.Soil_Type10[cc1] == True:\n",
    "                count_n3 += 1\n",
    "            else:\n",
    "                count_n4 += 1\n",
    "                \n",
    "                \n",
    "        \n",
    "    count_list3 += [count_n3]\n",
    "    count_list4 += [count_n4]\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_list5 = []\n",
    "count_list6 = []\n",
    "for numsons in range(1,8):\n",
    "    count_n5 = 0\n",
    "    count_n6 = 0\n",
    "    for cc2 in range(len(dataset.Cover_Type)):\n",
    "        \n",
    "        if dataset.Cover_Type[cc2] == numsons:\n",
    "            if dataset.Soil_Type14[cc2] == True:\n",
    "                count_n5 += 1\n",
    "            else:\n",
    "                count_n6 += 1\n",
    "                \n",
    "                \n",
    "        \n",
    "    count_list5 += [count_n5]\n",
    "    count_list6 += [count_n6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print('Soil Type4:',count_list5)\n",
    "print('no Soil Type4:',count_list6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Wilderness_Area4':count_list,'no Wilderness_Area4':count_list2,'Cover_Type': [1,2,3,4,5,6,7]})\n",
    "\n",
    "ax = df.plot.bar(rot=0,x = 'Cover_Type')\n",
    "ax.set_ylabel('count')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Soil_Type10':count_list3,'no Soil_Type10':count_list4,'Cover_Type': [1,2,3,4,5,6,7]})\n",
    "\n",
    "ax = df.plot.bar(rot=0,x = 'Cover_Type')\n",
    "ax.set_ylabel('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Soil_Type4':count_list5,'no Soil_Type4':count_list6,'Cover_Type': [1,2,3,4,5,6,7]})\n",
    "ax.set_ylabel('count')\n",
    "\n",
    "ax = df.plot.bar(rot=0,x = 'Cover_Type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset2 = dataset.drop(\"Wilderness_Area1\",1)\n",
    "dataset2 =  dataset2.drop(\"Wilderness_Area2\",1)\n",
    "dataset2 = dataset2.drop(\"Wilderness_Area3\",1)\n",
    "dataset2 =  dataset2.drop(\"Wilderness_Area4\",1)\n",
    "Wilderness_Area1 = []\n",
    "Wilderness_Area2 = []\n",
    "Wilderness_Area3 = []\n",
    "Wilderness_Area4 = []\n",
    "for ele1 in dataset.Wilderness_Area1:\n",
    "    Wilderness_Area1 += [ele1]\n",
    "for ele2 in dataset.Wilderness_Area2:\n",
    "    Wilderness_Area2 += [ele2]\n",
    "for ele3 in dataset.Wilderness_Area3:\n",
    "    Wilderness_Area3 += [ele3]\n",
    "for ele4 in dataset.Wilderness_Area4:\n",
    "    Wilderness_Area4 += [ele4]\n",
    "Wilderness_Area_type = []\n",
    "for columns in range(len(dataset.Wilderness_Area1)):\n",
    "    if Wilderness_Area1[columns] == True:\n",
    "        Wilderness_Area_type += [\"Wilderness_Area1\"]\n",
    "    if Wilderness_Area2[columns] == True:\n",
    "        Wilderness_Area_type += [\"Wilderness_Area2\"]\n",
    "    if Wilderness_Area3[columns] == True:\n",
    "        Wilderness_Area_type += [\"Wilderness_Area3\"]\n",
    "    if Wilderness_Area4[columns] == True:\n",
    "        Wilderness_Area_type += [\"Wilderness_Area4\"]\n",
    "dataset2['Wilderness_Area_type'] = Wilderness_Area_type\n",
    "    \n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_csv = dataset2.to_csv (r'dataset2.csv', index = None, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "eledata = dataset.Slope\n",
    "eleset = set(eledata)\n",
    "eledata2 = list(eleset)\n",
    "print(len(eleset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "numsons3 = 0\n",
    "\n",
    "for cols in dataset2:\n",
    "    if numsons3>= 10 and numsons3 < 50: \n",
    "    \n",
    "        dataset2[cols] = dataset2[cols].astype('bool')\n",
    "    numsons3 += 1\n",
    "numsons4 = 0    \n",
    "for cols1 in dataset2:\n",
    "    if numsons4 < 10: \n",
    "    \n",
    "        dataset2[cols1] = dataset2[cols1].astype('float64')\n",
    "    numsons4 += 1\n",
    "\n",
    "sto = []\n",
    "for data_item in dataset2.Wilderness_Area_type:\n",
    "    if data_item == 'Wilderness_Area1':\n",
    "        sto += [1]\n",
    "    if data_item == 'Wilderness_Area2':\n",
    "        sto += [2]\n",
    "    if data_item == 'Wilderness_Area3':\n",
    "        sto += [3]\n",
    "    if data_item == 'Wilderness_Area4':\n",
    "        sto += [4]\n",
    "    \n",
    "print(len(sto))\n",
    "dataset2.Wilderness_Area_type = sto\n",
    "dataset2.Wilderness_Area_type.astype('category')\n",
    "\n",
    "dataset2.Cover_Type.astype('category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try_model = DecisionTreeClassifier()\n",
    "try_model.fit(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = dataset2.drop(\"Cover_Type\",1)   #Feature Matrix\n",
    "b = dataset2[\"Cover_Type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset2.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2['Cover_Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = dataset2.groupby('Cover_Type')\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import f_classif\n",
    "bestfeatures2 = SelectKBest(score_func=f_classif , k=10)\n",
    "\n",
    "\n",
    "fit2 = bestfeatures.fit(a,b)\n",
    "dfscores2 = pd.DataFrame(fit2.scores_)\n",
    "dfcolumns2 = pd.DataFrame(a.columns)\n",
    "#concat two dataframes for better visualization \n",
    "featureScores2 = pd.concat([dfcolumns2,dfscores2],axis=1)\n",
    "featureScores2.columns = ['Specs','Score']  #naming the dataframe columns\n",
    "print(featureScores2.nlargest(51,'Score')) \n",
    "print(featureScores2.nlargest(51,'Score').Specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccc = 0\n",
    "list_import_l = []\n",
    "for att in featureScores2.nlargest(51,'Score').Score:\n",
    "    if att > 1000:\n",
    "        \n",
    "        ccc += 1\n",
    "\n",
    "ccc1 = 0\n",
    "    \n",
    "for att_t  in featureScores2.nlargest(51,'Score').Specs:\n",
    "    if ccc1 >= ccc:\n",
    "        list_import_l += [att_t]\n",
    "    ccc1 += 1\n",
    "print(list_import_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for removing in list_import_l:\n",
    "    dataset2 = dataset2.drop(removing,1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = dataset2['Elevation'].hist(bins=3)\n",
    "hist.set_ylabel('count')\n",
    "\n",
    "hist.set_xlabel('Elevation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Elevation_group = []\n",
    "for group1 in dataset2['Elevation']:\n",
    "    if group1 < 2600:\n",
    "        Elevation_group += [1]\n",
    "    elif group1 >= 2600  and group1 < 3200:\n",
    "        \n",
    "        Elevation_group += [2]\n",
    "        \n",
    "    else:\n",
    "        Elevation_group += [3]\n",
    "dataset2['Elevation_group'] =  Elevation_group\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_list_ele = []\n",
    "c1 = 0\n",
    "c2 = 0\n",
    "c3 = 0\n",
    "for count_ma in Elevation_group:\n",
    "    if count_ma == 1:\n",
    "        c1 += 1\n",
    "    elif count_ma == 2:\n",
    "        c2 += 1\n",
    "    else:\n",
    "        c3 += 1\n",
    "count_list_ele += [c1]\n",
    "count_list_ele += [c2]\n",
    "count_list_ele += [c3]\n",
    "df = pd.DataFrame({'count': count_list_ele,'Elevation_group':[1,2,3]})\n",
    "ax = df.plot.bar(rot=0,x = 'Elevation_group')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = dataset2.drop(\"Cover_Type\",1)\n",
    "B = dataset2['Cover_Type']\n",
    "from sklearn.model_selection import train_test_split\n",
    "A_train, A_test, B_train, B_test = train_test_split(A, B, \n",
    "test_size=1/5, random_state=0)\n",
    "print('train:',len(A_train))\n",
    "print('test',len(A_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model_first =  RandomForestClassifier(n_estimators = 5,criterion = 'entropy')\n",
    "model_second = RandomForestClassifier(n_estimators = 10,criterion = 'entropy')\n",
    "model_third = RandomForestClassifier(n_estimators = 10,criterion = 'gini')\n",
    "model_forth = RandomForestClassifier(n_estimators = 5,criterion = 'gini')\n",
    "model_first.fit(A_train,B_train)\n",
    "model_second.fit(A_train,B_train)\n",
    "model_third.fit(A_train,B_train)\n",
    "model_forth.fit(A_train,B_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    errors = abs(predictions - test_labels)\n",
    "    mape = 100 * np.mean(errors / test_labels)\n",
    "    accuracy = 100 - mape\n",
    "    print('Model Performance')\n",
    "    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
    "    print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model_first,A_test,B_test)\n",
    "evaluate(model_second,A_test,B_test)\n",
    "evaluate(model_third,A_test,B_test)\n",
    "evaluate(model_forth,A_test,B_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp1 = MLPClassifier(activation='relu', max_iter=100)\n",
    "\n",
    "mlp1.fit(A_train, B_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp2 = MLPClassifier(activation='identity', max_iter=100)\n",
    "\n",
    "mlp2.fit(A_train, B_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp3 = MLPClassifier(activation='logistic', max_iter=100)\n",
    "\n",
    "mlp3.fit(A_train, B_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp4 = MLPClassifier(activation='tanh', max_iter=100)\n",
    "\n",
    "mlp4.fit(A_train, B_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp5 = MLPClassifier(activation='relu', max_iter=200)\n",
    "\n",
    "mlp5.fit(A_train, B_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp6 = MLPClassifier(activation='relu', max_iter =150)\n",
    "mlp6.fit(A_train, B_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(mlp6,A_test,B_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_model_first = model_first.predict(A_test)\n",
    "prediction_model_second = model_second.predict(A_test)\n",
    "prediction_model_third = model_third.predict(A_test)\n",
    "prediction_model_forth = model_forth.predict(A_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
    "\n",
    "print(\"accuracy for model_first: \" + str(accuracy_score(B_test, prediction_model_first)*100) +\"%\")\n",
    "print(\"accuracy for model_second: \" + str(accuracy_score(B_test, prediction_model_second)*100) +\"%\")\n",
    "print(\"accuracy for model_third: \" + str(accuracy_score(B_test, prediction_model_third)*100) + \"%\")\n",
    "print(\"accuracy for model_forth: \" + str(accuracy_score(B_test, prediction_model_forth)*100) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_mlp1 = mlp1.predict(A_test)\n",
    "prediction_mlp2 = mlp2.predict(A_test)\n",
    "prediction_mlp3 = mlp3.predict(A_test)\n",
    "prediction_mlp4 = mlp4.predict(A_test)\n",
    "prediction_mlp5 = mlp5.predict(A_test)\n",
    "prediction_mlp6 = mlp6.predict(A_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"accuracy for mlp1: \" + str(accuracy_score(B_test, prediction_mlp1)*100) +\"%\")\n",
    "print(\"accuracy for mlp2: \" + str(accuracy_score(B_test, prediction_mlp2)*100) +\"%\")\n",
    "print(\"accuracy for mlp3: \" + str(accuracy_score(B_test, prediction_mlp3)*100) + \"%\")\n",
    "print(\"accuracy for mlp4: \" + str(accuracy_score(B_test, prediction_mlp4)*100) + \"%\")\n",
    "print(\"accuracy for mlp5: \" + str(accuracy_score(B_test, prediction_mlp5)*100) +\"%\")\n",
    "print(\"accuracy for mlp6: \" + str(accuracy_score(B_test, prediction_mlp6)*100) +\"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_second.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance1 = []\n",
    "feature_importance2 = []\n",
    "feature_list = []\n",
    "for fff in A_train:\n",
    "    feature_list += [fff]\n",
    "for i in model_second.feature_importances_:\n",
    "    feature_importance1 += [i]\n",
    "    feature_importance2 += [i]\n",
    "feature_importance1 = sorted(feature_importance1, reverse=True)\n",
    "feature_importance_rank = []\n",
    "for t in feature_importance1:\n",
    "    pos = feature_importance2.index(t)\n",
    "    feature_importance_rank += [feature_list[pos]]\n",
    "print(feature_importance_rank)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = []\n",
    "for all_features in dataset2:\n",
    "    if all_features != \"Cover_Type\":\n",
    "        \n",
    "        tt += [all_features]\n",
    "print(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt2 = []\n",
    "for tttt in range(10,52):\n",
    "    tt2 += [tt[tttt]]\n",
    "print(tt2)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt2 += [\"Cover_Type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt3 = []\n",
    "for newt in range(0,10):\n",
    "    tt3 += [tt[newt]]\n",
    "print(tt3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(dataset2.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/home/ubuntu/spark-2.1.1-bin-hadoop2.7')\n",
    "import pyspark\n",
    "from pyspark.sql import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('missing').getOrCreate()\n",
    "df_spark = spark.createDataFrame(dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in tt2:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_spark.select(*(df_spark[c].cast(\"integer\").alias(c) for c in tt2),*(df_spark[x].cast(\"float\").alias(x) for x in tt3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df.withColumn(\"Elevation\", df_spark[\"Elevation\"])\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler,VectorIndexer,OneHotEncoder,StringIndexer\n",
    "assembler = VectorAssembler(inputCols=tt, outputCol='features5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark = assembler.transform(df_spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark.select(\"features5\").show()\n",
    "df_spark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = StringIndexer(inputCol=\"Cover_Type\", outputCol=\"PrivateIndex\")\n",
    "output_fixed = indexer.fit(output).transform(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainingData, testData) = df_spark.randomSplit([0.8, 0.2])\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import (RandomForestClassifier, GBTClassifier, DecisionTreeClassifier)\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "rf1 = RandomForestClassifier(labelCol=\"Cover_Type\", featuresCol=\"features5\", numTrees=10,impurity = 'gini')\n",
    "rf2 = RandomForestClassifier(labelCol=\"Cover_Type\", featuresCol=\"features5\", numTrees=10,impurity = 'entropy')\n",
    "rf3 = RandomForestClassifier(labelCol=\"Cover_Type\", featuresCol=\"features5\", numTrees=5,impurity = 'gini')\n",
    "rf4 = RandomForestClassifier(labelCol=\"Cover_Type\", featuresCol=\"features5\", numTrees=5,impurity = 'entropy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf1 = rf1.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf2 = rf2.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf3 = rf3.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf4 = rf4.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf5 = RandomForestClassifier(labelCol=\"Cover_Type\", featuresCol=\"features5\", numTrees=10,impurity = 'gini',maxDepth = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf5 =  rf5.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred5 = model_rf5.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingData.print().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = DecisionTreeClassifier(labelCol=\"Cover_Type\", featuresCol=\"features5\",maxDepth = 5,impurity = 'gini')\n",
    "d2 = DecisionTreeClassifier(labelCol=\"Cover_Type\", featuresCol=\"features5\",maxDepth = 8,impurity = 'entropy')\n",
    "d3 = DecisionTreeClassifier(labelCol=\"Cover_Type\", featuresCol=\"features5\",maxDepth = 5,impurity = 'entropy')\n",
    "d4 = DecisionTreeClassifier(labelCol=\"Cover_Type\", featuresCol=\"features5\",maxDepth = 8,impurity = 'gini')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_d1 = d1.fit(trainingData)\n",
    "model_d2 = d2.fit(trainingData)\n",
    "model_d3 = d3.fit(trainingData)\n",
    "model_d4 = d4.fit(trainingData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d5 = DecisionTreeClassifier(labelCol=\"Cover_Type\", featuresCol=\"features5\",maxDepth = 15,impurity = 'gini')\n",
    "model_d5 = d5.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_d5.featureImportances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred5 = model_d5.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare = []\n",
    "for l in range(len(tt)):\n",
    "    compare += [model_d5.featureImportances[l]]\n",
    "\n",
    "compare2 = compare[:]\n",
    "compare2.sort(reverse=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking = []\n",
    "for l2 in compare2:\n",
    "    ranking += [tt[compare.index(l2)]]\n",
    "print(ranking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = model_rf1.transform(testData)\n",
    "pred2 = model_rf2.transform(testData)\n",
    "pred3 = model_rf3.transform(testData)\n",
    "pred4 = model_rf4.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import (RandomForestClassifier, GBTClassifier, DecisionTreeClassifier)\n",
    "G1 = GBTClassifier(labelCol=\"Cover_Type\", featuresCol=\"features5\")\n",
    "G2 = GBTClassifier(labelCol=\"Cover_Type\", featuresCol=\"features5\",stepSize = 0.2,maxDepth = 5,maxIter = 1)\n",
    "G3 = GBTClassifier(labelCol=\"Cover_Type\", featuresCol=\"features5\",stepSize = 0.1,maxDepth = 10)\n",
    "G4 = GBTClassifier(labelCol=\"Cover_Type\", featuresCol=\"features5\",stepSize = 0.2,maxDepth = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_G1 = G2.fit(trainingData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = model_rf1.transform(testData)\n",
    "pred2 = model_rf2.transform(testData)\n",
    "pred3 = model_rf3.transform(testData)\n",
    "pred4 = model_rf4.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2.select(\"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pred1.select(\"Cover_Type\",pred1.prediction.cast('long').alias('prediction_new'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1.select(\"Cover_Type\",\"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1.createOrReplaceTempView('people')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView('ppp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1.select(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2 = pred1.withColumn(\"predicition_new\",df[\"prediction_new\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "nb = NaiveBayes(labelCol=\"Cover_Type\", featuresCol=\"features5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model4 = nb.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import MultilayerPerceptronClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainer = MultilayerPerceptronClassifier(maxIter=100, blockSize=128, seed=1234)\n",
    "trainer = MultilayerPerceptronClassifier(maxIter=100, blockSize=128, seed=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = MultilayerPerceptronClassifier(labelCol=\"Cover_Type\", featuresCol=\"features5\",maxIter=1, layers=[1, 1, 1], blockSize=1, seed=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = trainer.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DoubleType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_evaluator = MulticlassClassificationEvaluator(labelCol=\"Cover_Type\", predictionCol=\"prediction\", metricName=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_acc1 = acc_evaluator.evaluate(pred1)\n",
    "print(\"accuracy for model_rf1:\",dtc_acc1)\n",
    "dtc_acc2 = acc_evaluator.evaluate(pred2)\n",
    "print(\"accuracy for model_rf2:\",dtc_acc2)\n",
    "dtc_acc3 = acc_evaluator.evaluate(pred3)\n",
    "print(\"accuracy for model_rf3:\",dtc_acc3)\n",
    "dtc_acc4 = acc_evaluator.evaluate(pred4)\n",
    "print(\"accuracy for model_rf4:\",dtc_acc4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_acc5 = acc_evaluator.evaluate(pred5)\n",
    "print(\"accuracy for model_d5:\",dtc_acc5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred5 = pred5.select(\"prediction\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = testData.select(\"Cover_Type\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred5.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred5.prediction.astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(df_test, df_pred5)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')\n",
    "\n",
    "\n",
    "sns.boxplot(data = dataset2, x = 'Cover_Type', y = 'Horizontal_Distance_To_Roadways')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2.plot.scatter(x='Cover_Type',y='Horizontal_Distance_To_Roadways')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')\n",
    "\n",
    "\n",
    "sns.boxplot(data = dataset2, x = 'Cover_Type', y = 'Horizontal_Distance_To_Fire_Points')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax2 = dataset2.plot.scatter(x='Cover_Type',\n",
    "                       y = 'Horizontal_Distance_To_Fire_Points'\n",
    "                       \n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset2[dataset2.Cover_Type == 3]\n",
    "ax = sns.distplot(df['Horizontal_Distance_To_Roadways'],  kde=False, label='3')\n",
    "ax.set(xlabel='Horizontal_Distance_To_Roadways', ylabel='count',title = 'class 3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset2[dataset2.Cover_Type == 6]\n",
    "ax = sns.distplot(df['Horizontal_Distance_To_Roadways'],  kde=False, label='6')\n",
    "ax.set(xlabel='Horizontal_Distance_To_Roadways', ylabel='count',title = 'class 6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset2[dataset2.Cover_Type == 2]\n",
    "ax = sns.distplot(df['Horizontal_Distance_To_Fire_Points'],  kde=False, label='class 2')\n",
    "ax.set(xlabel='Horizontal_Distance_To_Fire_Points', ylabel='count',title = 'class 2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset2[dataset2.Cover_Type == 1]\n",
    "ax = sns.distplot(df['Horizontal_Distance_To_Fire_Points'],  kde=False, label='class 1')\n",
    "ax.set(xlabel='Horizontal_Distance_To_Fire_Points', ylabel='count',title = 'class 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(B_test, prediction_model_second)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
